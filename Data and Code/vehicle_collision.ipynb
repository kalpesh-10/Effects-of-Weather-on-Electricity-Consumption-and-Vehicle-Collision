{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X20181663- DAP PROJECT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### installing and Importing  the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests\n",
    "!pip install pymongo\n",
    "!pip install pypyodbc\n",
    "!pip install folium\n",
    "!pip install sodapy\n",
    "\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from sodapy import Socrata\n",
    "import matplotlib.pyplot as plt \n",
    "import os\n",
    "from pymongo import MongoClient\n",
    "import psycopg2\n",
    "import io\n",
    "import pandas.io.sql as sqlio\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the data from source and storing the dataset in MongoDB cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id=\"h9gi-nx95\"\n",
    "rows_limit=100000\n",
    "db_name=\"MONGO_DB_DAP_PROJ\"\n",
    "username= \"dap\"\n",
    "password = \"dap\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for connecting to MongoDb and the inserting the Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def db_connect(dataset_id,data_limit,db_name):\n",
    "    flag=0\n",
    "    try:\n",
    "        client = Socrata(\"data.cityofnewyork.us\", None)\n",
    "        raw_data = client.get(dataset_id, where = \"crash_date >'2019-12-31'\", limit=data_limit)\n",
    "        print(\"Data fetched\")\n",
    "        flag=1\n",
    "    except:\n",
    "        print(\"API connection Error\")\n",
    "    \n",
    "    if(flag==1):\n",
    "        try:\n",
    "            #mongoDb cloud connection\n",
    "            client = MongoClient(\"mongodb://%s:%s@127.0.0.1\" % (username, password))\n",
    "            mongo_db = client[db_name]\n",
    "            collection =mongo_db.db_name\n",
    "            print(\"Dataset and collection created\")\n",
    "            \n",
    "            #clear existing records from database\n",
    "            db_del_data= collection.remove() \n",
    "        \n",
    "            #Pushing unstructed json data into MongoDb cloud.\n",
    "            db_mongo_inserted= collection.insert_many(raw_data)\n",
    "        \n",
    "            print(\"JSON Data injected in the MongoDB \")\n",
    "        \n",
    "            #iterating over the injected data\n",
    "            db_mongo_inserted=collection.find().limit(5);\n",
    "            for data in db_mongo_inserted: \n",
    "                print(data)\n",
    "            return collection\n",
    "        except Exception as e: print(e)\n",
    "            \n",
    "        finally:\n",
    "            client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_collection=db_connect(dataset_id,rows_limit,db_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting data from collection in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list=list(raw_collection.find({}))\n",
    "raw_dataframe=pd.DataFrame(df_list)\n",
    "raw_dataframe.info() \n",
    "raw_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning (Removing Null values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_percent_missing =pd.DataFrame(raw_dataframe.isnull().sum() * 100 / len(raw_dataframe))\n",
    "df_percent_missing.columns=['Null_Percentage']\n",
    "df_percent_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing columns having not null values less than 40% of the total rows.\n",
    "raw_dataframe.dropna(axis=1, how=\"any\", thresh=len(raw_dataframe)*.40, inplace=True)\n",
    "\n",
    "#removing rows for the columns having null values less than 10%\n",
    "cols_to_delete = raw_dataframe.columns[raw_dataframe.isnull().sum()/len(raw_dataframe) < .10]\n",
    "raw_dataframe.dropna(axis=0, how=\"any\", thresh=None, subset=cols_to_delete.values, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing the null values with their mode as all the columns are catagorical in nature.\n",
    "columns_to_replace = raw_dataframe.columns[raw_dataframe.isnull().sum()/len(raw_dataframe) !=.00]\n",
    "\n",
    "for i in columns_to_replace:\n",
    "    raw_dataframe[i].fillna(raw_dataframe[i].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformation (Renaming and removing columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing location column from the dataframe as we cannot calculate mode for the combined location data.\n",
    "del raw_dataframe['location']\n",
    "\n",
    "#We would not loose any information in this process as we could use latitude and longitude columns for generating location.\n",
    "raw_dataframe[\"LOCATION\"]=raw_dataframe[\"latitude\"] + raw_dataframe[\"longitude\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Rename columns for the better understanding of the data.\n",
    "\n",
    "raw_dataframe.rename(columns = {'_id'                  : 'MONGODB_ID',\n",
    "                       'on_street_name'                : 'ON_STREET',\n",
    "                       'off_street_name'               : 'OFF_STREET',\n",
    "                       'number_of_persons_injured'     : 'NUM_PER_INJURED',\n",
    "                       'number_of_persons_killed'      : 'NUM_PER_KILLED',\n",
    "                       'number_of_pedestrians_injured' : 'NUM_PED_INJURED',\n",
    "                       'number_of_pedestrians_killed'  : 'NUM_PED_KILLED',\n",
    "                       'number_of_cyclist_injured'     : 'NUM_CYCL_INJURED',\n",
    "                       'number_of_cyclist_killed'      : 'NUM_CYCL_KILLED',\n",
    "                       'number_of_motorist_injured'    : 'NUM_MOTOR_INJURED',\n",
    "                       'number_of_motorist_killed'     : 'NUM_MOTOR_KILLED',\n",
    "                       'contributing_factor_vehicle_1' : 'VEH_FACTOR_1',\n",
    "                       'contributing_factor_vehicle_2' : 'VEH_FACTOR_2',\n",
    "                       'vehicle_type_code1'            : 'VEH_TYPE_1',\n",
    "                       'vehicle_type_code2'            : 'VEH_TYPE_2'}, inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatinating columns for better analysis of the data. also changing the datatypes of the column.\n",
    "\n",
    "raw_dataframe['DATE'] = raw_dataframe['crash_date'] + ' ' + raw_dataframe['crash_time']\n",
    "raw_dataframe['DATE'] = pd.to_datetime(raw_dataframe.DATE)\n",
    "\n",
    "raw_dataframe['year'] = raw_dataframe['DATE'].dt.year\n",
    "raw_dataframe['month'] = raw_dataframe['DATE'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing object datatypes to int for numeric values columns\n",
    "raw_dataframe['zip_code'] =raw_dataframe['zip_code'].astype(int,errors='ignore')\n",
    "raw_dataframe['NUM_PER_INJURED'] =raw_dataframe['NUM_PER_INJURED'].astype(int,errors='ignore')\n",
    "raw_dataframe['NUM_PER_KILLED'] =raw_dataframe['NUM_PER_KILLED'].astype(int,errors='ignore')\n",
    "raw_dataframe['NUM_PED_INJURED'] =raw_dataframe['NUM_PED_INJURED'].astype(int,errors='ignore')\n",
    "raw_dataframe['NUM_PED_KILLED'] =raw_dataframe['NUM_PED_KILLED'].astype(int,errors='ignore')\n",
    "raw_dataframe['NUM_CYCL_INJURED'] =raw_dataframe['NUM_CYCL_INJURED'].astype(int,errors='ignore')\n",
    "raw_dataframe['NUM_CYCL_KILLED'] =raw_dataframe['NUM_CYCL_KILLED'].astype(int,errors='ignore')\n",
    "raw_dataframe['NUM_MOTOR_INJURED'] =raw_dataframe['NUM_MOTOR_INJURED'].astype(int,errors='ignore')\n",
    "\n",
    "#changing object datatypes to string for string values columns \n",
    "raw_dataframe['VEH_TYPE_1'] =raw_dataframe['VEH_TYPE_1'].astype(str,errors='ignore')\n",
    "raw_dataframe['VEH_TYPE_2'] =raw_dataframe['VEH_TYPE_2'].astype(str,errors='ignore')\n",
    "raw_dataframe['borough'] =raw_dataframe['borough'].astype(str,errors='ignore')\n",
    "raw_dataframe['ON_STREET'] =raw_dataframe['ON_STREET'].astype(str,errors='ignore')\n",
    "raw_dataframe['OFF_STREET'] =raw_dataframe['OFF_STREET'].astype(str,errors='ignore')\n",
    "\n",
    "\n",
    "# changing string to numeric\n",
    "raw_dataframe[\"latitude\"] = raw_dataframe[\"latitude\"].astype(float,errors='ignore')\n",
    "raw_dataframe[\"longitude\"] = raw_dataframe[\"longitude\"].astype(float,errors='ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw_dataframe.dtypes)\n",
    "print(\"\\n*******************************\")\n",
    "raw_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting cleaned and transformed file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataframe.to_csv('C:/Users/DEV/Desktop/nyc_car_colision_data.csv')\n",
    "del raw_dataframe['MONGODB_ID']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Injecting the data in PostgreSQL for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postgreConnection():\n",
    "    dbConnection = psycopg2.connect(\n",
    "        user = username, \n",
    "        password = password,\n",
    "        host = \"127.0.0.1\",\n",
    "        port = \"5432\",\n",
    "        database = \"collision\")\n",
    "    return dbConnection\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    dbConnection = postgreConnection()\n",
    "    dbConnection.set_isolation_level(0) # AUTOCOMMIT\n",
    "    dbCursor = dbConnection.cursor()\n",
    "    dbCursor.execute('CREATE DATABASE collision')\n",
    "    dbCursor.close()\n",
    "except (Exception , psycopg2.Error) as dbError :\n",
    "    print (\"Error while connecting to PostgreSQL\", dbError)\n",
    "finally:\n",
    "        if dbConnection in locals(): \n",
    "            dbConnection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    sql = '''DROP TABLE IF EXISTS NYC_VEHICLE_COLLISION_DATA'''\n",
    "    dbCursor.execute(sql)\n",
    "except (Exception , psycopg2.Error) as dbError :\n",
    "    print (\"Error while connecting to PostgreSQL\", dbError)\n",
    "finally:\n",
    "        if dbConnection in locals(): \n",
    "            dbConnection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "#PostgreSQL connection .\n",
    "connection='postgresql://dap:dap@localhost:5432/collision'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function def for injecting data to postgreSQL\n",
    "def data_insert_postgreSQL(tbName, dataframe,con,sql_cursor):\n",
    "    try:\n",
    "        engine = create_engine(con)\n",
    "        dataframe.to_sql(tbName, con=engine, if_exists='replace')\n",
    "    except (Exception , psycopg2.Error) as dbError :\n",
    "        print (\"Error while connecting to PostgreSQL\", dbError)\n",
    "    finally:\n",
    "        if dbConnection in locals(): \n",
    "            dbConnection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_insert_postgreSQL('NYC_VEHICLE_COLLISION_DATA',raw_dataframe,connection,dbCursor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching the injected data from PostgreSQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fetch_data(query):\n",
    "    try:\n",
    "        dbConnection = postgreConnection()\n",
    "        sql=query\n",
    "        clean_dataframe = sqlio.read_sql_query(sql, dbConnection)\n",
    "        return clean_dataframe\n",
    "    except (Exception , psycopg2.Error) as dbError :\n",
    "        print (\"Error while connecting to PostgreSQL\", dbError)\n",
    "    finally:\n",
    "        if dbConnection in locals(): \n",
    "            dbConnection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query='''SELECT * FROM public.\"NYC_VEHICLE_COLLISION_DATA\"'''\n",
    "cleaned_df=fetch_data(sql_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df.info()\n",
    "cleaned_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization with fetch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ggplot\n",
    "!pip install plotly\n",
    "#import ggplot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "#import folium\n",
    "import datetime\n",
    "import calendar\n",
    "import folium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot for accidents happening in different boroughs in New York City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot 1\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title('Collision in different Boroughs',fontsize=30)\n",
    "plt.xlabel('Boroughs',fontsize=20)\n",
    "plt.ylabel('Accident Count',fontsize=20)\n",
    "sns.barplot(x=cleaned_df.groupby('borough').size().index,\n",
    "            y=cleaned_df.groupby('borough').size().values, palette = 'viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot for different reasons behind the accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot 2\n",
    "FACTOR_1 = cleaned_df.groupby('VEH_FACTOR_1').size().sort_values(ascending=True)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.title('Reasons for Accidents', fontsize=30)\n",
    "plt.ylabel('Reasons',fontsize=20)\n",
    "plt.xlabel('Accident Count', fontsize=20)\n",
    "sns.barplot(y = FACTOR_1.index, x = FACTOR_1.values, palette = 'flare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLot 3: Bar plot displaying the count of injured and killed persons with respect to different accident types(pedestrain,cyclist,motorist)\n",
    "\n",
    "df_injured = cleaned_df[[i for i in cleaned_df.columns for c in ['NUM_PED_INJURED', 'NUM_CYCL_INJURED', 'NUM_MOTOR_INJURED'] if c in i]].sum()\n",
    "df_injured.index = ['Pedestrian', 'Cyclist', 'Motorist']\n",
    "plt.suptitle('PLOT FOR COUNT OF PERSONS INJURED PER ACCIDENT TYPE', fontsize=25, x=0.5,y=1.02)\n",
    "sns.barplot(df_injured.index, df_injured.values, palette='viridis')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot for displaying the exact location of accidents in the city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot 4\n",
    "map_df = cleaned_df.dropna(subset=['latitude', 'longitude'])\n",
    "map = folium.Map(location=[40.767937,-73.982155 ], zoom_start=10) \n",
    "\n",
    "for collision in map_df[0:100].iterrows():\n",
    "    folium.Marker([collision[1]['latitude'],\n",
    "                   collision[1]['longitude']]).add_to(map)\n",
    "display(map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 Vehicles in collisions\n",
    "v_cols = [c for c in cleaned_df.columns if c.startswith(\"VEH_TYPE_1\")]\n",
    "v_cols\n",
    "vehicles = cleaned_df[v_cols]\n",
    "vehicles_1d = vehicles.stack()\n",
    "vehicles_counts = vehicles_1d.value_counts()\n",
    "top10_vehicles = vehicles_counts.head(10)\n",
    "print(\"Top 10 Vehicles in Accidents\")\n",
    "top10_vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weatherData = pd.read_csv(\"C:/Users/DEV/Desktop/weather.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_insert_postgreSQL('WEATHER_DATA',weatherData,connection,dbCursor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query='''SELECT * FROM public.\"NYC_VEHICLE_COLLISION_DATA\" WHERE \"year\" = 2020;'''\n",
    "col21Data=fetch_data(sql_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query='''SELECT * FROM public.\"WEATHER_DATA\" WHERE \"year\" = 2020;'''\n",
    "wthr21Data=fetch_data(sql_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cd = pd.merge(wthr21Data, col21Data, how='inner', on = 'month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot 1: Month Wise Distribution\n",
    "FACTOR_1 = df_cd.groupby('month').size().sort_values(ascending=True)\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.title('Accidents distribution month wise', fontsize=30)\n",
    "plt.ylabel('Count',fontsize=20)\n",
    "plt.xlabel('Accident Count', fontsize=20)\n",
    "sns.barplot(y = FACTOR_1.values, x =FACTOR_1.index  , palette = 'cubehelix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot 2: Month Wise Temp\n",
    "df_cd_1 = df_cd[['month','temp']]\n",
    "df_cd_2= df_cd_1.groupby(['month'],as_index=False).mean()\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.title('Temperature across different months in 2020 in New York', fontsize=25)\n",
    "sns.barplot(y = df_cd_2['temp'], x =df_cd_2['month']  , palette = 'rocket')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot 3: Month Wise Visibility\n",
    "df_cd_3 = df_cd[['month','visibility']]\n",
    "df_cd_4= df_cd_3.groupby(['month'],as_index=False).mean()\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.title('Visibility across different months in 2020 in New York', fontsize=25)\n",
    "sns.barplot(y = df_cd_4['visibility'], x =df_cd_4['month']  , palette = 'crest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
